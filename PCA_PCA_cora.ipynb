{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA-PCA on cora Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting/Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'CAGE' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import functools as ft\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, rand_score\n",
    "from sklearn import model_selection as sk_ms\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import preprocessing\n",
    "import functools as ft\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, rand_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from nltk.cluster.util import cosine_distance, euclidean_distance\n",
    "from nltk.cluster.kmeans import KMeansClusterer\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import networkx as nx\n",
    "from sklearn.svm import SVC  # or another classifier of your choice\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class Util_class():\n",
    "\n",
    "  \"\"\"\n",
    "  dict_in : dictionary\n",
    "  list_key : list of key\n",
    "  return True if ALL key in list_key is in dict\n",
    "  \"\"\"\n",
    "  def check_key_in_dict(dict_in, list_key):\n",
    "    is_in = True\n",
    "    list_not_in = []\n",
    "    for key in list_key:\n",
    "      if key not in dict_in:\n",
    "        is_in = False\n",
    "        list_not_in.append(key)\n",
    "    return [is_in,list_not_in]\n",
    "\n",
    "  def same_key_in_dict(dict_in, list_key):\n",
    "    is_in = True\n",
    "    key_not_dict = []\n",
    "    key_not_list = []\n",
    "\n",
    "    for key in list_key:\n",
    "      if key not in dict_in:\n",
    "        is_in = False\n",
    "        key_not_dict.append(key)\n",
    "\n",
    "    for key in dict_in:\n",
    "      if key not in list_key:\n",
    "        is_in = False\n",
    "        key_not_list.append(key)\n",
    "    return [is_in,key_not_dict,key_not_list]\n",
    "\n",
    "  def folder_manage(path, uniquify=True,clean=False, force=False):\n",
    "    last_folder = os.path.basename(os.path.normpath(path))\n",
    "    head_path = os.path.dirname(os.path.normpath(path))\n",
    "\n",
    "    #head of path exist\n",
    "    if os.path.exists(head_path):\n",
    "        #path last folder not exist\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "            return os.path.normpath(path)\n",
    "        #path last folder  exist\n",
    "        else:\n",
    "            if uniquify:\n",
    "                counter = 1\n",
    "                while os.path.exists(path):\n",
    "                    path = head_path + \"/\" + last_folder  + \"(\" + str(counter) + \")\"\n",
    "                    counter += 1\n",
    "                os.makedirs(path)\n",
    "            #empty last folder\n",
    "            elif clean:\n",
    "                if force:\n",
    "                    shutil.rmtree(path)\n",
    "                    os.makedirs(path)\n",
    "                else:\n",
    "                    print(f'Enter YES or Y to delete all file or directory from: {path}')\n",
    "                    input_clean = input()\n",
    "                    if input_clean in [\"YES\",\"Y\",\"yes\",\"y\"]:\n",
    "                        shutil.rmtree(path)\n",
    "                        os.makedirs(path)\n",
    "                    else:\n",
    "                        raise Util_class_folder_manage_forceDelete(path)\n",
    "        return os.path.normpath(path)\n",
    "    else:\n",
    "        print(f'Enter YES or Y to create directories: {path}')\n",
    "        input_clean = input()\n",
    "        if input_clean in [\"YES\",\"Y\",\"yes\",\"y\"]:\n",
    "            os.makedirs(path)\n",
    "            return os.path.normpath(path)\n",
    "        else:\n",
    "            raise Util_class_folder_manage_dirnameNotExist(head_path)\n",
    "\n",
    "class Util_class_folder_manage_dirnameNotExist(Exception):\n",
    "    \"\"\"Exception raised for errors in activation function type\"\"\"\n",
    "\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Directory name '{self.value}' not exist.\"\n",
    "\n",
    "class Util_class_folder_manage_forceDelete(Exception):\n",
    "    \"\"\"Exception raised for errors in activation function type\"\"\"\n",
    "\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Not possible force clean the folder: '{self.value}'.\"\n",
    "\n",
    "\n",
    "datase_name = 'cora'\n",
    "path_models_checkpoint = '/content/models_checkpoint'\n",
    "Util_class.folder_manage(path_models_checkpoint)\n",
    "path = '/content/dataset/'\n",
    "Util_class.folder_manage(path)\n",
    "!git clone https://github.com/MIND-Lab/CAGE.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class PerformanceEmbedding():\n",
    "\n",
    "    def __init__(self, model, labels, embedding_name='att', node_label='node_label'):\n",
    "        if not isinstance(model, GraphEModel):\n",
    "            raise PerformanceEmbedding_notModelClass(model)\n",
    "        self.embedding = model.get_embedding(phase=embedding_name, type_output=\"numpy\")\n",
    "        self.labels = labe\n",
    "        self.group_by = ['avg','sum']\n",
    "        self.cluster_measure = ['rand_score']\n",
    "        self.classifier_measure = ['accuracy_score','precision_macro','precision_micro','precision_weighted',\n",
    "                                   'recall_macro','recall_micro','recall_weighted',\n",
    "                                   'f1_macro','f1_micro','f1_weighted']\n",
    "\n",
    "    def visualization(self):\n",
    "        visualemb = VisualEmbedding(self.embedding,self.labels)\n",
    "        return visualemb.embedding_visualization(None)\n",
    "\n",
    "    def classification(self, repetitions = 10, classifier_name = \"svm\", performance_group_by='avg',labeled_data_threshold=None, measures_selected = None, random_set = True):\n",
    "        if measures_selected is None:\n",
    "            measures_selected = self.classifier_measure\n",
    "        else:\n",
    "            for meas in measures_selected:\n",
    "                if meas not in self.classifier_measure:\n",
    "                    raise PerformanceEmbedding_notMeasureExperiment(meas,'NodeClassification')\n",
    "        if labeled_data_threshold is None:\n",
    "            labeled_data_threshold = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "\n",
    "        n_classify = NodeClassification(self.embedding,self.labels, normalize=True)\n",
    "        measures = dict()\n",
    "        for split_threshold in labeled_data_threshold:\n",
    "            measure = n_classify.classification(classifier_name, split_threshold, repetitions, self.group_by, random_set)\n",
    "            _key = \"split_\"+str(split_threshold)\n",
    "            measures[_key] = measure\n",
    "\n",
    "        return self.performance_measure(measures,measures_selected,performance_group_by)\n",
    "\n",
    "    def clusterization(self, repetitions = 10, performance_group_by='avg', measures_selected = None):\n",
    "        if measures_selected is None:\n",
    "            measures_selected = self.cluster_measure\n",
    "        else:\n",
    "            for meas in measures_selected:\n",
    "                if meas not in self.cluster_measure:\n",
    "                    raise PerformanceEmbedding_notMeasureExperiment(meas,'NodeClustering')\n",
    "\n",
    "        n_clusterfy = NodeClustering(self.embedding,self.labels)\n",
    "        measures = dict()\n",
    "        measure = n_clusterfy.classic_clusterizzation(repetitions, self.group_by)\n",
    "        measures[\"all\"] = measure\n",
    "        return self.performance_measure(measures,measures_selected,performance_group_by)\n",
    "\n",
    "\n",
    "    def performance_measure(self, measures, measures_selected, groub_by='avg',):\n",
    "        pd_measure = pd.DataFrame()\n",
    "        pd_measure['name_measure'] = measures_selected\n",
    "\n",
    "        for split_name in measures:\n",
    "            val_col = list()\n",
    "            for meas_name in measures_selected:\n",
    "                if meas_name not in measures[split_name][groub_by]:\n",
    "                    raise PerformanceEmbedding_notMeasure(meas_name)\n",
    "                else:\n",
    "                    val_col.append(measures[split_name][groub_by][meas_name])\n",
    "            pd_measure[split_name] = val_col\n",
    "        pd_measure.set_index('name_measure')\n",
    "        return pd_measure\n",
    "\n",
    "\n",
    "    def loss_plot(self):\n",
    "        data_plot_losses = [val.item() for val in DAGE_values['losses']]\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.plot(data_plot_losses,\"b.\")\n",
    "\n",
    "\n",
    "\n",
    "class PerformanceEmbedding_notModelClass(Exception):\n",
    "      \"\"\"Exception raised for not classifier type found\"\"\"\n",
    "\n",
    "      def __init__(self, obj):\n",
    "          self.obj = obj\n",
    "\n",
    "      def __str__(self):\n",
    "          return f\"Model should be a 'GraphEModel' class object but receive a ''{type(self.obj)} object.\"\n",
    "\n",
    "class PerformanceEmbedding_notMeasure(Exception):\n",
    "      \"\"\"Exception raised for not classifier type found\"\"\"\n",
    "\n",
    "      def __init__(self, name_measure):\n",
    "          self.name_measure = name_measure\n",
    "\n",
    "      def __str__(self):\n",
    "          return f\"Percormance '{self.name_measure}' not recognized.\"\n",
    "\n",
    "class PerformanceEmbedding_notMeasureExperiment(Exception):\n",
    "      \"\"\"Exception raised for not classifier type found\"\"\"\n",
    "\n",
    "      def __init__(self, measure_name, experiment_name):\n",
    "          self.measure_name = measure_name\n",
    "          self.experiment_name = experiment_name\n",
    "\n",
    "      def __str__(self):\n",
    "          return f\"Experiment '{self.experiment_name}' not implement performance called '{self.measure_name}'.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadDataset():\n",
    "\n",
    "    def __init__(self,edge_file_name,attribute_file_name,label_file_name,attribute_file_format=\"normalized_matrix\",is_directed_graph=False):\n",
    "        \"\"\"\n",
    "        edge_file : file with all edge (pair of nodes)\n",
    "        attribute_file : file with all attribute\n",
    "        label_file :\n",
    "        attribute_file_format : format od attribute data:\n",
    "              \"normal_matrix\" : each row is alredy a frequency normalizzated vector (DEFAULT) es: CORA dataset\n",
    "              \"naive_text\" : each row is item text description\n",
    "        is_directed_graph : boolean, if true is a direct graph else (DEFAULT) is a undirect graph\n",
    "\n",
    "        \"\"\"\n",
    "        self.is_directed_graph = is_directed_graph\n",
    "        #input shape\n",
    "        self.input_shape = dict()\n",
    "\n",
    "        #Structural preprocessing\n",
    "        self.edge_file_name = edge_file_name\n",
    "        self.graph = self.edge_createGraph()\n",
    "        #Changed due to nx not containing function\n",
    "        self.edge_adj_matrix = np.array(nx.to_numpy_array(self.graph, nodelist=sorted(self.graph.nodes())))\n",
    "\n",
    "        #Attribute preprocessing\n",
    "        self.attribute_file_name = attribute_file_name\n",
    "        self.attribute_adj_matrix = np.array(self.attribute_createMatrix(attribute_file_format))\n",
    "\n",
    "        #Class preprocessing\n",
    "        self.label_file_name = label_file_name\n",
    "        self.label_vec = self.labels_createVector()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def get_structural_matrix(self):\n",
    "        return self.edge_adj_matrix\n",
    "\n",
    "    def get_attribute_matrix(self):\n",
    "        return self.attribute_adj_matrix\n",
    "\n",
    "    def get_vector_matrix(self):\n",
    "        return self.label_vec\n",
    "\n",
    "    def get_graph(self):\n",
    "        return self.graph\n",
    "\n",
    "    def export_graph(self, pathfile, filename, extention=\"graphml\"):\n",
    "        path = pathfile+'/'+filename+'.'+extention\n",
    "\n",
    "        if extention == \"graphml\":\n",
    "            nx.write_graphml( self.graph, path)\n",
    "        elif extention == \"gml\":\n",
    "            nx.write_gml( self.graph, path)\n",
    "        else:\n",
    "            raise LoadDataset_Exception_Graph_FormatExport_notRecognized(extention)\n",
    "        return True\n",
    "\n",
    "    def get_input_shape(self, key):\n",
    "        return self.input_shape[key]\n",
    "\n",
    "    def edge_createGraph(self):\n",
    "        if self.is_directed_graph:\n",
    "            g = nx.DiGraph()\n",
    "        else:\n",
    "            g = nx.Graph()\n",
    "        try:\n",
    "            with open(self.edge_file_name, 'r') as edge_file:\n",
    "                for line in edge_file:\n",
    "                    edge = line.split()\n",
    "                    if len(edge) == 3:\n",
    "                        edge_weight = float(edge[2])\n",
    "                    else:\n",
    "                        edge_weight = 1.0\n",
    "                    if len(edge) == 1:\n",
    "                        g.add_node(int(edge[0]))\n",
    "                    else:\n",
    "                        g.add_edge(int(edge[0]), int(edge[1]), weight = edge_weight)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        self.input_shape['net'] = g.number_of_nodes()\n",
    "        print(\"Structure dimension:\\t\",self.input_shape['net'])\n",
    "        return g\n",
    "\n",
    "    def attribute_createMatrix(self, attribute_file_format):\n",
    "        if attribute_file_format == \"normalized_matrix\":\n",
    "            try:\n",
    "                att_matrix = []\n",
    "                with open(self.attribute_file_name, 'r') as att_file:\n",
    "                    for line in att_file:\n",
    "                      att_line = line.replace(\"\\n\", \"\").split(\" \")[1:]\n",
    "                      att_matrix.append([float(n) for n in att_line])\n",
    "                self.input_shape['att'] = len(att_matrix[0])\n",
    "                print(\"Attribute dimension:\\t\",self.input_shape['att'])\n",
    "                return att_matrix\n",
    "            except Exception as e:\n",
    "                raise e\n",
    "        elif attribute_file_format == \"naive_text\":\n",
    "            print(\"naive_text to do\")\n",
    "            try:\n",
    "                att_matrix = []\n",
    "                with open(self.attribute_file_name, 'r') as att_file:\n",
    "                    for line in att_file:\n",
    "                        print(line)\n",
    "                        break\n",
    "                    corpus = json.load(att_file)\n",
    "                    print(corpus)\n",
    "\n",
    "                return 0\n",
    "            except Exception as e:\n",
    "                raise e\n",
    "        else:\n",
    "            raise(LoadDataset_Exception_Attribute_Format_notRecognized(attribute_file_format))\n",
    "\n",
    "\n",
    "    def labels_createVector(self):\n",
    "        try:\n",
    "            with open(self.label_file_name, 'r') as label_file:\n",
    "                node_label_dict = {}\n",
    "                for line in label_file:\n",
    "                    split_line = line.replace(\"\\n\", \"\").split(\" \")\n",
    "                    node_id = int(split_line[0])\n",
    "                    node_label = int(split_line[1])\n",
    "                    node_label_dict[node_id] = node_label\n",
    "                # sort the keys (node_ids) of the dictionary\n",
    "                node_label_dict = OrderedDict(sorted(node_label_dict.items(), key=lambda t: t[0]))\n",
    "                labels = np.array(list(node_label_dict.values()))\n",
    "                return labels\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    def get_labels(self):\n",
    "        return self.label_vec\n",
    "\n",
    "\n",
    "class LoadDataset_Exception_Attribute_Format_notRecognized(Exception):\n",
    "      \"\"\"Exception raised for errors in list of layers type\"\"\"\n",
    "\n",
    "      def __init__(self, value):\n",
    "          self.value = value\n",
    "\n",
    "      def __str__(self):\n",
    "          return f'{self.value} : type of attribute file format not recognized.'\n",
    "\n",
    "class LoadDataset_Exception_Graph_FormatExport_notRecognized(Exception):\n",
    "      \"\"\"Exception raised for errors in list of layers type\"\"\"\n",
    "\n",
    "      def __init__(self, value):\n",
    "          self.value = value\n",
    "\n",
    "      def __str__(self):\n",
    "          return f'{self.value} : graph format export not recognized.'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeClassification():\n",
    "\n",
    "    def __init__(self, embedding_data, labels, normalize=False):\n",
    "        if normalize:\n",
    "            self.data = pd.DataFrame(preprocessing.normalize(embedding_data, norm='l2', axis=1))\n",
    "        else:\n",
    "            self.data = pd.DataFrame(embedding_data)\n",
    "        self.oper_math = ['sum', 'avg']\n",
    "        self.labels = labels\n",
    "        self.performal_measure = {\n",
    "            \"accuracy_score\" : ft.partial(accuracy_score),\n",
    "            \"precision_macro\" : ft.partial(precision_score, average='macro'),\n",
    "            \"precision_micro\" : ft.partial(precision_score, average='micro'),\n",
    "            \"recall_macro\" : ft.partial(recall_score, average='macro'),\n",
    "            \"recall_micro\" : ft.partial(recall_score, average='micro'),\n",
    "            \"f1_macro\" : ft.partial(f1_score, average='macro', labels=np.unique(self.labels)),\n",
    "            \"f1_micro\" : ft.partial(f1_score, average='micro', labels=np.unique(self.labels)),\n",
    "\n",
    "            \"precision_weighted\" : ft.partial(precision_score, average='weighted'),\n",
    "            \"recall_weighted\" : ft.partial(recall_score, average='weighted'),\n",
    "            \"f1_weighted\" : ft.partial(f1_score, average='weighted', labels=np.unique(self.labels)),\n",
    "        }\n",
    "\n",
    "    def split_dataset(self, split_threshold, num_split, random_set):\n",
    "        \"\"\"\n",
    "        split_threshold : float, threshold of test split\n",
    "        num_split : int, number of split\n",
    "        random_set : boolean, TRUE if each split is randomly different by others\n",
    "        return : array, where each item is a dictionary of data's split, with keys X_train, X_test, Y_train, Y_test\n",
    "        \"\"\"\n",
    "        data_splitted = list()\n",
    "        _splitted_data = None\n",
    "        for i in range(num_split):\n",
    "            if random_set or (_splitted_data == None):\n",
    "                X_train, X_test, Y_train, Y_test = sk_ms.train_test_split(self.data, self.labels, test_size=split_threshold)\n",
    "                _splitted_data = {\n",
    "                    \"X_train\" : X_train,\n",
    "                    \"Y_train\" : Y_train,\n",
    "                    \"X_test\" : X_test,\n",
    "                    \"Y_test\" : Y_test,\n",
    "                }\n",
    "            data_splitted.append(_splitted_data)\n",
    "        return data_splitted\n",
    "\n",
    "\n",
    "\n",
    "    def classification(self, classifier_name, split_threshold, repetitions, group_by, random_set):\n",
    "        \"\"\"\n",
    "        classifier_name : string, name of classifier. Implemented \"svm\",\n",
    "        split_threshold : float, threshold of test split\n",
    "        repetitions : int, number of repetitions of classification\n",
    "        random_set : boolean, TRUE if each split is randomly different by others\n",
    "        group_by : array, math operation group by measure\n",
    "        return : array, each item is a data's split\n",
    "        \"\"\"\n",
    "        data_splitted = self.split_dataset(split_threshold, repetitions, random_set)\n",
    "\n",
    "        if classifier_name == \"svm\":\n",
    "            classifier = LinearSVC()\n",
    "        else:\n",
    "            raise NodeClassification_notClassifierFound(classifier_name)\n",
    "        measures_performance = dict()\n",
    "\n",
    "        for n_repetition in range(repetitions):\n",
    "            data_split = data_splitted.pop(0)\n",
    "            classifier.fit(data_split[\"X_train\"], data_split[\"Y_train\"])\n",
    "            predictions = self.prediction(classifier, data_split[\"X_test\"])\n",
    "            performance_computation = self.performance_computation(data_split[\"Y_test\"], predictions)\n",
    "\n",
    "            key_iter = \"iter_\"+str(n_repetition)\n",
    "            measures_performance[key_iter] = performance_computation\n",
    "\n",
    "        measure_total = dict()\n",
    "        for oper in group_by:\n",
    "            if oper in self.oper_math:\n",
    "                measure_total[oper] = dict()\n",
    "                for measure_name in self.performal_measure:\n",
    "                      measure_total[oper][measure_name] = list()\n",
    "            else:\n",
    "                raise NodeClassification_notAggregationRecognizer(oper)\n",
    "\n",
    "        for iteration_measure in measures_performance:\n",
    "            for measure_name in self.performal_measure:\n",
    "                value = measures_performance[iteration_measure][measure_name]\n",
    "                for oper in group_by:\n",
    "                    measure_total[oper][measure_name].append(value)\n",
    "        for oper in group_by:\n",
    "            for measure_name in self.performal_measure:\n",
    "                if oper == \"avg\":\n",
    "                    measure_total[oper][measure_name] = sum(measure_total[oper][measure_name])/len(measure_total[oper][measure_name])\n",
    "                elif oper == \"sum\":\n",
    "                    measure_total[oper][measure_name] = sum(measure_total[oper][measure_name])\n",
    "                else:\n",
    "                    measure_total[oper][measure_name] = 0\n",
    "        return measure_total\n",
    "\n",
    "\n",
    "    def prediction(self, model, data):\n",
    "        return model.predict(data)\n",
    "\n",
    "    def performance_computation(self, Y_test, Y_pred):\n",
    "        performance_measure_computed = dict()\n",
    "\n",
    "        for measure_name in self.performal_measure:\n",
    "            measure_function = self.performal_measure[measure_name]\n",
    "            measure_value = measure_function(Y_test, Y_pred)\n",
    "            performance_measure_computed[measure_name] = measure_value\n",
    "        return performance_measure_computed\n",
    "\n",
    "\n",
    "class NodeClassification_notClassifierFound(Exception):\n",
    "      \"\"\"Exception raised for not classifier type found\"\"\"\n",
    "\n",
    "      def __init__(self, name):\n",
    "          self.name = name\n",
    "\n",
    "      def __str__(self):\n",
    "          return f\"{type(self.name)} : type of classifier not found.\"\n",
    "\n",
    "class NodeClassification_notAggregationRecognizer(Exception):\n",
    "      \"\"\"Exception raised for not classifier type found\"\"\"\n",
    "\n",
    "      def __init__(self, name):\n",
    "          self.name = name\n",
    "\n",
    "      def __str__(self):\n",
    "          return f\" Classification not support '{type(self.name)}' group_by. It's accept: 'sum' or 'avg'.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structure dimension:\t 2708\n",
      "Attribute dimension:\t 1433\n",
      "cora\n"
     ]
    }
   ],
   "source": [
    "edge_file_name = f\"/Users/darkr/OneDrive/Documents/GitHub/CAGE/data/{datase_name}/in_edges.txt\"\n",
    "attribute_file_name = f\"/Users/darkr/OneDrive/Documents/GitHub/CAGE/data/{datase_name}/in_features.txt\"\n",
    "label_file_name = f\"/Users/darkr/OneDrive/Documents/GitHub/CAGE/data/{datase_name}/in_group.txt\"\n",
    "\n",
    "path_model_checkpoint = f\"/content/models_checkpoint/CAGE_{datase_name}\"\n",
    "Util_class.folder_manage(path_model_checkpoint)\n",
    "\n",
    "is_directed_graph = False\n",
    "attribute_file_format = \"normalized_matrix\"\n",
    "dataLoad = LoadDataset(edge_file_name,attribute_file_name,label_file_name,attribute_file_format=attribute_file_format,is_directed_graph=is_directed_graph)\n",
    "\n",
    "dataLoad.export_graph(f\"/content/models_checkpoint/CAGE_{datase_name}\",f\"CAGE_{datase_name}_graph\")\n",
    "net_adj = dataLoad.get_structural_matrix()\n",
    "att_adj = dataLoad.get_attribute_matrix()\n",
    "label_vec = dataLoad.get_labels()\n",
    "print(datase_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes in labels: [0 1 2 3 4 5 6]\n",
      "Classification Accuracy: 0.3025830258302583\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC  # or another classifier of your choice\n",
    "\n",
    "def read_edges(file_path):\n",
    "    # Read edges from a text file and return a list of tuples (edges)\n",
    "    edges = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            node1, node2 = line.strip().split()\n",
    "            edges.append((int(node1), int(node2)))  # Convert to integers\n",
    "    return edges\n",
    "\n",
    "def read_features(file_path):\n",
    "    # Read features from a text file and return a numpy array\n",
    "    return np.loadtxt(file_path, delimiter=' ')\n",
    "\n",
    "def create_adjacency_matrix(edges, num_nodes):\n",
    "    # Create an adjacency matrix from a list of edges\n",
    "    adjacency_matrix = np.zeros((num_nodes, num_nodes))\n",
    "    for node1, node2 in edges:\n",
    "        adjacency_matrix[int(node1), int(node2)] = 1\n",
    "        adjacency_matrix[int(node2), int(node1)] = 1  # Assuming undirected graph\n",
    "    return adjacency_matrix\n",
    "\n",
    "def apply_pca(data, n_components=2):\n",
    "    # Apply PCA to the given data\n",
    "    pca = PCA(n_components=n_components)\n",
    "    return pca.fit_transform(data)\n",
    "\n",
    "def read_labels(label_file_path):\n",
    "    \"\"\"\n",
    "    Read node labels/groups from a text file and return a 1D numpy array.\n",
    "    Assumes the first column is the node number and the second column is the label.\n",
    "    \"\"\"\n",
    "    all_data = np.loadtxt(label_file_path, dtype=int)\n",
    "    labels = all_data[:, 1]  # Extract only the second column for labels\n",
    "    return labels\n",
    "\n",
    "def main(edge_file_name, attribute_file_name, label_file_name):\n",
    "    # Read data\n",
    "    edges = read_edges(edge_file_name)\n",
    "    features = read_features(attribute_file_name)\n",
    "    labels = read_labels(label_file_name)\n",
    "    unique_classes = np.unique(labels)\n",
    "    print(\"Unique classes in labels:\", unique_classes)\n",
    "\n",
    "    # Apply PCA to the features\n",
    "    pca_features = apply_pca(features)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(pca_features, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "    # Train a classifier\n",
    "    classifier = SVC()  # Support Vector Classifier\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predict and calculate accuracy\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Classification Accuracy:\", accuracy)\n",
    "\n",
    "    return pca_features, labels\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    edge_file_name = f\"/Users/darkr/OneDrive/Documents/GitHub/CAGE/data/{datase_name}/in_edges.txt\"\n",
    "    attribute_file_name = f\"/Users/darkr/OneDrive/Documents/GitHub/CAGE/data/{datase_name}/in_features.txt\"\n",
    "    label_file_name = f\"/Users/darkr/OneDrive/Documents/GitHub/CAGE/data/{datase_name}/in_group.txt\"\n",
    "    pca_embedding, labels = main(edge_file_name, attribute_file_name, label_file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes in labels: [0 1 2 3 4 5 6]\n",
      "Classification Accuracy: 0.3025830258302583\n",
      "PCA Embeddings Shape: (2708, 2)\n",
      "Labels Shape: (2708,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg': {'accuracy_score': 0.2968634686346864, 'precision_macro': 0.04240906694781233, 'precision_micro': 0.2968634686346864, 'recall_macro': 0.14285714285714282, 'recall_micro': 0.2968634686346864, 'f1_macro': 0.06535461254973766, 'f1_micro': 0.2968634686346864, 'precision_weighted': 0.08848974006345231, 'recall_weighted': 0.2968634686346864, 'f1_weighted': 0.13624464942120898}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"cora\"  # Replace with your dataset name\n",
    "\n",
    "# Read embeddings and labels from the main function\n",
    "pca_embeddings, labels = main(edge_file_name, attribute_file_name, label_file_name)\n",
    "\n",
    "print(\"PCA Embeddings Shape:\", pca_embeddings.shape)\n",
    "print(\"Labels Shape:\", labels.shape)\n",
    "\n",
    "node_classifier = NodeClassification(pca_embeddings, labels, normalize=True)\n",
    "evaluation_results = node_classifier.classification(classifier_name=\"svm\", split_threshold=0.2, repetitions=10, group_by=[\"avg\"], random_set=True)\n",
    "\n",
    "print(evaluation_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA PCA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes in labels: [0 1 2 3 4 5 6]\n",
      "Classification Accuracy: 0.3025830258302583\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import networkx as nx\n",
    "from sklearn.svm import SVC  # or another classifier of your choice\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def read_edges(file_path):\n",
    "    # Read edges from a text file and return a list of tuples (edges)\n",
    "    edges = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            node1, node2 = line.strip().split()\n",
    "            edges.append((int(node1), int(node2)))  # Convert to integers\n",
    "    return edges\n",
    "\n",
    "def read_features(file_path):\n",
    "    # Read features from a text file and return a numpy array\n",
    "    return np.loadtxt(file_path, delimiter=' ')\n",
    "\n",
    "def create_adjacency_matrix(edges, num_nodes):\n",
    "    # Create an adjacency matrix from a list of edges\n",
    "    adjacency_matrix = np.zeros((num_nodes, num_nodes))\n",
    "    for node1, node2 in edges:\n",
    "        adjacency_matrix[int(node1), int(node2)] = 1\n",
    "        adjacency_matrix[int(node2), int(node1)] = 1  # Assuming undirected graph\n",
    "    return adjacency_matrix\n",
    "\n",
    "def apply_pca(data, n_components=2):\n",
    "    # Apply PCA to the given data\n",
    "    pca = PCA(n_components=n_components)\n",
    "    return pca.fit_transform(data)\n",
    "\n",
    "def read_labels(file_path):\n",
    "    \"\"\"\n",
    "    Read node labels/groups from a text file and return a 1D numpy array.\n",
    "    Assumes the first column is the node number and the second column is the label.\n",
    "    \"\"\"\n",
    "    all_data = np.loadtxt(file_path, dtype=int)\n",
    "    labels = all_data[:, 1]  # Extract only the second column for labels\n",
    "    return labels\n",
    "\n",
    "def merge_embeddings(structural_embedding, attribute_embedding):\n",
    "    \"\"\"\n",
    "    Merge structural and attribute embeddings by concatenation.\n",
    "    \"\"\"\n",
    "    return np.concatenate((structural_embedding, attribute_embedding), axis=1)\n",
    "\n",
    "def main(dataset_name):\n",
    "    # Read data\n",
    "    edges = read_edges(edge_file_name)\n",
    "    features = read_features(attribute_file_name)\n",
    "    labels = read_labels(label_file_name)\n",
    "    unique_classes = np.unique(labels)\n",
    "    print(\"Unique classes in labels:\", unique_classes)\n",
    "\n",
    "    # Create a graph from edges\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(edges)\n",
    "\n",
    "    # Get number of nodes\n",
    "    num_nodes = max(max(edge) for edge in edges) + 1\n",
    "\n",
    "    # Create adjacency matrix\n",
    "    adjacency_matrix = create_adjacency_matrix(edges, num_nodes)\n",
    "\n",
    "    # Apply PCA for Structural Embedding\n",
    "    structural_embedding = apply_pca(adjacency_matrix)\n",
    "\n",
    "    # Apply PCA for Attribute Embedding\n",
    "    attribute_embedding = apply_pca(features)\n",
    "\n",
    "    # Merge Structural and Attribute Embeddings\n",
    "    merged_embedding = merge_embeddings(structural_embedding, attribute_embedding)\n",
    "\n",
    "    # Node Classification\n",
    "    X_train, X_test, y_train, y_test = train_test_split(merged_embedding, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "    classifier = SVC()  # Support Vector Classifier\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Classification Accuracy:\", accuracy)\n",
    "\n",
    "    return(merged_embedding)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_name = \"cora\"  # Replace with your dataset name\n",
    "    main(dataset_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes in labels: [0 1 2 3 4 5 6]\n",
      "Classification Accuracy: 0.3025830258302583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg': {'accuracy_score': 0.285239852398524, 'precision_macro': 0.04074855034264628, 'precision_micro': 0.285239852398524, 'recall_macro': 0.14285714285714282, 'recall_micro': 0.285239852398524, 'f1_macro': 0.06337637029030267, 'f1_micro': 0.285239852398524, 'precision_weighted': 0.08161245081085497, 'recall_weighted': 0.285239852398524, 'f1_weighted': 0.1268451127649292}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\darkr\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"cora\"  # Replace with your dataset name\n",
    "\n",
    "# Read embeddings and labels\n",
    "pca_pca_embedding = main(dataset_name)\n",
    "labels = read_labels(label_file_name)\n",
    "\n",
    "node_classifier = NodeClassification(pca_pca_embedding, labels, normalize=True)\n",
    "evaluation_results = node_classifier.classification(classifier_name=\"svm\", split_threshold=0.2, repetitions=10, group_by=[\"avg\"], random_set=True)\n",
    "\n",
    "print(evaluation_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
